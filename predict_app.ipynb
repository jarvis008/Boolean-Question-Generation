{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4ea8778-a001-43c2-80a9-c184b1478029",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4ea8778-a001-43c2-80a9-c184b1478029",
        "outputId": "77aaae3b-f52f-4657-ee80-ec91804427d8",
        "tags": []
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install gradio\n",
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "192315d1-7a66-418f-b4ad-93b62b42d474",
      "metadata": {
        "id": "192315d1-7a66-418f-b4ad-93b62b42d474"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "import torch\n",
        "from time import time\n",
        "import gradio as gr\n",
        "from transformers import AutoTokenizer, T5ForConditionalGeneration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64dbe771-2693-4eb9-baee-e02e31aefb35",
      "metadata": {
        "id": "64dbe771-2693-4eb9-baee-e02e31aefb35"
      },
      "outputs": [],
      "source": [
        "def load_model(model_name):\n",
        "    device = torch.device('cuda:0') if torch.cuda.is_available() else 'cpu'\n",
        "    if model_name == 't5-small':\n",
        "        tokenizer_name = \"t5-small\"\n",
        "        path = \"arver/t5-small-boolean-qgen\"\n",
        "    elif model_name == 't5-base-finetuned':\n",
        "        tokenizer_name = \"t5-base\"\n",
        "        path = \"arver/t5-base-boolean-qgen-direct-finetune\"\n",
        "    elif model_name == 't5-base-qgen-finetuned':\n",
        "        tokenizer_name = \"t5-base\"\n",
        "        path = \"arver/t5-base-boolean-qgen_pretrained-finetuned\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
        "    model = T5ForConditionalGeneration.from_pretrained(path)\n",
        "    return tokenizer, model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffffde54-f651-4dd3-820c-7e80bd094590",
      "metadata": {
        "id": "ffffde54-f651-4dd3-820c-7e80bd094590",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def process_one_sample(tokenizer, context, answer, device, max_len=256, truncation=True, pad_to_max_len=True):\n",
        "  tokenizer_input = \"answer: %s context: %s\" % (answer, context)\n",
        "  tokenized_input = tokenizer(tokenizer_input, max_length=max_len, truncation=truncation, pad_to_max_length=pad_to_max_len, return_tensors='pt')\n",
        "  return tokenized_input['input_ids'].to(device), tokenized_input['attention_mask'].to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcdc623c-321d-4e15-8b4d-6a3b7002c0c0",
      "metadata": {
        "id": "dcdc623c-321d-4e15-8b4d-6a3b7002c0c0"
      },
      "outputs": [],
      "source": [
        "def beam_search_decoding (tokenizer, model, inp_ids,attn_mask, num_beams=5, num_return_sequences=2):\n",
        "  beam_output = model.generate(input_ids=inp_ids,\n",
        "                                 attention_mask=attn_mask,\n",
        "                                 max_length=256,\n",
        "                               num_beams=num_beams,\n",
        "                               num_return_sequences=num_return_sequences,\n",
        "                               no_repeat_ngram_size=2,\n",
        "                               early_stopping=True\n",
        "                               )\n",
        "  Questions = [tokenizer.decode(out, skip_special_tokens=True, clean_up_tokenization_spaces=True) for out in\n",
        "               beam_output]\n",
        "  return [Question.strip().capitalize() for Question in Questions]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f99b5cb8-7e49-41cf-a8d8-a9a7665c0866",
      "metadata": {
        "id": "f99b5cb8-7e49-41cf-a8d8-a9a7665c0866"
      },
      "outputs": [],
      "source": [
        "def predict_question(model_name, context, answer, num_beams=5, num_return_sequences=2):\n",
        "    device = torch.device('cuda:0') if torch.cuda.is_available() else 'cpu'\n",
        "    tokenizer, model = load_model(model_name)\n",
        "    input_ids, attention_mask = process_one_sample(tokenizer, context, answer, device)\n",
        "    start = time()\n",
        "    questions = beam_search_decoding(tokenizer, model, input_ids, attention_mask, num_beams, num_return_sequences)\n",
        "    end = time()\n",
        "    output = \"\"\n",
        "    c = 1\n",
        "    for question in questions:\n",
        "        output += str(c) + \". \" + question + \"\\n\"\n",
        "        c += 1\n",
        "    output += \"\\nInference time: \" + str((end-start)*1000) + \" ms\"\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e511995a-d625-42f5-86f4-5e74e2325d19",
      "metadata": {
        "id": "e511995a-d625-42f5-86f4-5e74e2325d19"
      },
      "outputs": [],
      "source": [
        "sample_context_true = \"The states that have legislatively adopted stand-your-ground laws are Alabama, Alaska, Arizona, Florida, Georgia, Idaho, Indiana, Iowa, Kansas, Kentucky, Louisiana, Michigan, Mississippi, Missouri, Montana, Nevada, New Hampshire, North Carolina, Oklahoma, Pennsylvania, South Carolina, South Dakota, Tennessee, Texas, Utah, West Virginia, and Wyoming.\"\n",
        "sample_context_false = \"In geometric measurements, length is the most extended dimension of an object. In the International System of Quantities, length is any quantity with dimension distance. In other contexts, length is a measured dimension of an object. Length may be distinguished from height, which is vertical extent, and width or breadth, which are the distance from side to side, measuring across the object at right angles to the length. For example, it is possible to cut a length of wire shorter than the wire's width. In most systems of measurement, the unit of length is a base unit, from which other units are derived.\"\n",
        "generate_questions_ui = gr.Interface(\n",
        "    predict_question,\n",
        "    inputs=[\n",
        "        gr.Dropdown(\n",
        "            [\"t5-small\", \"t5-base-finetuned\", \"t5-base-qgen-finetuned\"], label=\"Select model\", info=\"t5-small version finetuned on boolq, t5-base version finetuned on boolq, t5 base version pretrained on qgen data then finetuned on boolq\"\n",
        "        ),\n",
        "        gr.Textbox(label=\"Context\"),\n",
        "        gr.Dropdown(\n",
        "            [\"TRUE\", \"FALSE\"], label=\"Answer\", info=\"select TRUE if answer to question generated should be true, else select FALSE\"\n",
        "        ),\n",
        "        gr.Slider(3, 10, value=5, label=\"Number of beams\", step=1, info=\"Choose betwen 3 and 10, leave at 5 if not sure\"),\n",
        "        gr.Slider(1, 5, value=5, label=\"Number of questions generated\", step=1, info=\"Choose betwen 1 and 5, leave at 2 if not sure\")\n",
        "    ],\n",
        "    outputs=gr.Textbox(label=\"Questions generated\"),\n",
        "    examples=[\n",
        "        [\"t5-base-qgen-finetuned\", sample_context_true, \"TRUE\", 5, 1],\n",
        "        [\"t5-base-qgen-finetuned\", sample_context_false, \"FALSE\", 10, 1]\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Z3xobFRvvaES",
      "metadata": {
        "id": "Z3xobFRvvaES"
      },
      "outputs": [],
      "source": [
        "generate_questions_ui.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46a26964-5a66-4c30-a094-d7402df703a7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 749
        },
        "id": "46a26964-5a66-4c30-a094-d7402df703a7",
        "outputId": "cf63d3d7-b1ae-4dc8-a704-34736bc78c3d"
      },
      "outputs": [],
      "source": [
        "generate_questions_ui.launch(share=True, debug=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
